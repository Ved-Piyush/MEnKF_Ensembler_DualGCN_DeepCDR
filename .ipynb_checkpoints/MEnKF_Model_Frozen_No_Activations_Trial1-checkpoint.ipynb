{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 01:57:15.724212: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-01 01:57:15.751118: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-01 01:57:15.901426: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-01 01:57:15.902756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 01:57:16.891202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6028973-9799-4d8a-b919-a8dd6283faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34242ac3-a983-4bab-b092-bfcea4f94a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(weights_ann_1[0].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758ac30a-bcc7-4b5e-9314-7fb85f284f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2548f2de-a4c3-4850-b5cc-439634f5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = samp_ann.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1338dc89-5540-4867-95a6-3d0ea7639cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1  = samp_ann.layers[1].output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a92b1e3-d9c6-4ce7-959d-aef1376a29d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427b0370-90df-4ab4-85b9-691d082750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06982568-e5c1-4712-895c-7b3d49a09040",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a71c4646-23a6-45ca-9ccc-aa4c3566d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann_params = samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, data3, data4, size_ens, var_weights = 1.0, var_weight_weights = 4.0, var_L = 1.0, var_D = 1.0):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data2, initial_ensembles2, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data3, initial_ensembles3, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data4, initial_ensembles4, size_ens = size_ens)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weight_weights, size_ens)\n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # initial_ensembles_for_L = generate_initial_ensembles(4, var_L, size_ens)\n",
    "    # initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)    \n",
    "    \n",
    "    initial_ensembles_for_D1 = generate_initial_ensembles(1, var_D, size_ens).reshape(-1,1)\n",
    "    # initial_ensembles_for_D2 = generate_initial_ensembles(1, var_D, size_ens).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D1_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    initial_ensembles_for_D2_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D3_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.concatenate((np.expand_dims(initial_ensembles_for_D1,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D1_zero,1), \n",
    "                                                      np.expand_dims(initial_ensembles_for_D2_zero,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D3_zero,1)), axis = 2)\n",
    "    \n",
    "    # print(X_t.shape, initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:], initial_ensembles_for_D[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a2f9ca-f4b4-445a-ab5f-e0f0557f54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44ed09c8-f6b0-4b40-86e0-1975541fd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fudging_beta = beta(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, data3, data4, combined_ensembles , size_ens, fudging_beta):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    # initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4):(4*params + 4 + 4 )]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    # +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    model_1 = softmax_weights[:, 0].reshape(-1,1) \n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 1].reshape(-1,1) \n",
    "    \n",
    "    model_3 = softmax_weights[:, 2].reshape(-1,1) \n",
    "    \n",
    "    model_4 = softmax_weights[:, 3].reshape(-1,1)\n",
    "    \n",
    "    sum_weights = model_1 + model_2 + model_3 + model_4\n",
    "    \n",
    "    \n",
    "    # model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "    model_1 = model_1/sum_weights\n",
    "    \n",
    "    model_2 = model_2/sum_weights\n",
    "    \n",
    "    model_3 = model_3/sum_weights\n",
    "    \n",
    "    model_4 = model_4/sum_weights\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_2)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data3, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_3)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data4, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_4)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    final_output = data1_out1 + data1_out2 + data2_out1 + data2_out2\n",
    "    \n",
    "    # weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles,final_output, model_1, model_2, model_3, model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6bd2eb3-86b7-41ed-81b4-4dd8e44e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation_test(data1, data2, data3, data4, combined_ensembles , size_ens):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    # initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :1].reshape(-1,1)\n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 1:2].reshape(-1,1) \n",
    "    \n",
    "    model_3 = softmax_weights[:, 2:3].reshape(-1,1) \n",
    "    \n",
    "    model_4 = softmax_weights[:, 3:4].reshape(-1,1)\n",
    "    \n",
    "    sum_weights = model_1 + model_2 + model_3 + model_4\n",
    "    \n",
    "    \n",
    "    # model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "    model_1 = model_1/sum_weights\n",
    "    \n",
    "    model_2 = model_2/sum_weights\n",
    "    \n",
    "    model_3 = model_3/sum_weights\n",
    "    \n",
    "    model_4 = model_4/sum_weights\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_2)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data3, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_3)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data4, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_4)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    final_output = data1_out1 + data1_out2 + data2_out1 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, final_output, model_1, model_2, model_3, model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = 4*(samp_ann.count_params() + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 1, 1, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ef8c41-26ff-4e49-98f8-8f6c31b4eb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, data3, data4, initial_ensembles, fudging_beta  =fudging_beta): \n",
    "    _,_, weighted_alogp, w1, w2, w3, w4 = forward_operation(data1, data2, data3, data4, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    return weighted_alogp, w1, w2, w3, w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37b60b37-92b1-4784-85fc-59a865d2398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_test(data1, data2, data3, data4, initial_ensembles): \n",
    "    _,_, weighted_alogp, w1, w2, w3, w4 = forward_operation_test(data1, data2, data3, data4, initial_ensembles, size_ens = size_ens)\n",
    "    return weighted_alogp, w1, w2, w3, w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, data3, data4, initial_ensembles, fudging_beta):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann_params + 1  + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t, _,_, _, _, _, _ = forward_operation(data1, data2, data3, data4, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, data3, data4, initial_ensembles, y_train, size_ens = size_ens, inflation_factor = 1.0, fudging_beta = fudging_beta, \n",
    "                        fudging_var = None):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, data3, data4, initial_ensembles, fudging_beta)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    if fudging_var is not None: \n",
    "        mean_vec = np.zeros((updated_ensemble.shape[1],))\n",
    "        cov_mat = np.identity(updated_ensemble.shape[1])*fudging_var\n",
    "        fudging_for_updated_ensembles = mvn(mean_vec, cov_mat)\n",
    "        fudging_for_updated_ensembles_vec = fudging_for_updated_ensembles.rvs(size_ens)\n",
    "        updated_ensemble = updated_ensemble + fudging_for_updated_ensembles_vec\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "381fc654-8877-41fd-840a-4b35153f923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cov(shape, initial_ensembles):\n",
    "    cov_part = initial_ensembles[:, -4:-3]\n",
    "    cov_part = cov_part.mean(0)\n",
    "    variances1 = tf.math.softplus(cov_part).numpy()\n",
    "    n = shape\n",
    "    return variances1, np.identity(n)*variances1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c59ea29-6484-40d5-8777-80cf9ca6cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7649cb4e-4909-404a-86db-cfb8fc2e078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data//gcn_cdr_train_pca.pickle\", \"rb\") as f: \n",
    "    catch_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f029a85a-6790-4635-b02f-a8dfd9346e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data//gcn_cdr_test_pca.pickle\", \"rb\") as f: \n",
    "    catch_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cbefaa8-c226-47fb-a972-1a8207d29766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "176445fb-4f30-421a-a710-339955111baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_train(catch_train, size): \n",
    "    idxes = random.sample(range(0, catch_train[0].shape[0]), k = size)\n",
    "    idxes = list(idxes)\n",
    "    data1, data2, data3, data4 = catch_train[0][idxes,:], catch_train[1][idxes,:], catch_train[2][idxes,:], catch_train[3][idxes,:]\n",
    "    \n",
    "    y_train = catch_train[-1][idxes].reshape(-1,1)\n",
    "    \n",
    "    return data1, data2, data3, data4, y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7c13b4e-c9b7-4b7f-bd6e-92ec93cd40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_test( catch_test, size): \n",
    "    idxes = random.sample(range(0, catch_test[0].shape[0]), k = size)\n",
    "    idxes = list(idxes)\n",
    "    data1, data2, data3, data4 = catch_test[0][idxes,:], catch_test[1][idxes,:], catch_test[2][idxes,:], catch_test[3][idxes,:]\n",
    "    y_train = catch_test[-1][idxes].reshape(-1,1)\n",
    "    return data1, data2, data3, data4, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2a4da04-1a68-4b91-ad62-e6c027c91fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1_train, data2_train, data3_train, data4_train, y_train =  prepare_data_train(catch_train, size = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e54f80e-5b8d-4f46-a24a-2514a3683a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1_test, data2_test, data3_test, data4_test, y_test =  prepare_data_test(catch_test, size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aadbd46f-4890-40cc-8176-f292b9c45cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(idx, var_weights = 1.0, var_weight_weights = 4.0, var_D = 1, inflation_factor = 1.6, fudging_beta = beta(1,19), \n",
    "               fudging_var = 1e-3, epochs = 30):\n",
    "    \n",
    "    # smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx, var_weights = var_weights, var_weight_weights =var_weight_weights, var_L = var_L, var_D = var_D)\n",
    "    \n",
    "    \n",
    "    data1_train, data2_train, data3_train, data4_train, y_train =  prepare_data_train(catch_train, size = 2500)\n",
    "    \n",
    "    data1_test, data2_test, data3_test, data4_test, y_test =  prepare_data_test(catch_test, size = 1000)\n",
    "    \n",
    "    X_t, initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_D = get_initial_X_t(data1_train, data2_train, data3_train, data4_train,\n",
    "                                                                                                 size_ens = size_ens, var_weights = var_weights,\n",
    "                                                                                                var_weight_weights = var_weight_weights, var_D = var_D)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_D))\n",
    "    \n",
    "    best_rmse_train = 100000\n",
    "    \n",
    "    for i in range(0,epochs):\n",
    "        print(\"epoch number is \" +str(i))\n",
    "\n",
    "        initial_ensembles = get_updated_ensemble(data1_train, data2_train, data3_train, data4_train, initial_ensembles, y_train, size_ens = size_ens,\n",
    "                                                 inflation_factor = inflation_factor, fudging_beta = fudging_beta, fudging_var = fudging_var)\n",
    "        \n",
    "        G_u_train, w1, w2, w3, w4 = get_predictions(data1_train, data2_train, data3_train, data4_train, initial_ensembles, fudging_beta)\n",
    "    \n",
    "        li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:].reshape(-1,1)    \n",
    "        ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:].reshape(-1,1)  \n",
    "    \n",
    "        width_train = ui_train - li_train\n",
    "        avg_width_train = width_train.mean(0)[0]\n",
    "    \n",
    "        ind_train = (y_train >= li_train) & (y_train <= ui_train)\n",
    "        coverage_train= ind_train.mean(0)[0]\n",
    "    \n",
    "        averaged_targets_train = G_u_train.mean(0).reshape(-1,1)\n",
    "        rmse_train = np.sqrt(((y_train -averaged_targets_train)**2).mean(0))[0]\n",
    "        \n",
    "        pearsonr_train = pearsonr(averaged_targets_train.reshape(averaged_targets_train.shape[0],), \n",
    "                                 y_train.reshape(y_train.shape[0],))\n",
    "        \n",
    "        r_train = pearsonr_train.statistic\n",
    "    \n",
    "        G_u_test, _, _, _, _ = get_predictions_test(data1_test, data2_test, data3_test, data4_test, initial_ensembles)\n",
    "    \n",
    "\n",
    "    \n",
    "        li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:].reshape(-1,1)     \n",
    "        ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:].reshape(-1,1)   \n",
    "    \n",
    "        width_test = ui_test - li_test\n",
    "        avg_width_test = width_test.mean(0)[0]\n",
    "    \n",
    "        ind_test = (y_test >= li_test) & (y_test <= ui_test)\n",
    "        coverage_test= ind_test.mean(0)[0]\n",
    "    \n",
    "        averaged_targets_test = G_u_test.mean(0).reshape(-1,1)\n",
    "        rmse_test = np.sqrt(((y_test -averaged_targets_test)**2).mean(0))[0]  \n",
    "        \n",
    "        pearsonr_test = pearsonr(averaged_targets_test.reshape(averaged_targets_test.shape[0],), \n",
    "                                 y_test.reshape(y_test.shape[0],))\n",
    "        \n",
    "        r_test = pearsonr_test.statistic\n",
    "\n",
    "        print(\"Training Coverage, Widths, RMSE, and Pearson R\")\n",
    "        print(coverage_train, avg_width_train, rmse_train, r_train)\n",
    "        print(\"Testing Coverage, Widths, RMSE, and Pearson R\")\n",
    "        print(coverage_test, avg_width_test, rmse_test, r_test)\n",
    "        # print(w1.mean(), w1.std())\n",
    "\n",
    "        if (rmse_train < best_rmse_train): \n",
    "            best_rmse_train = rmse_train\n",
    "            # print(\"went here\")\n",
    "            best_train_width_mean = avg_width_train.mean()\n",
    "            best_train_width = avg_width_train\n",
    "            # best_smiles_weight = w1.mean()\n",
    "            best_coverage_train = coverage_train\n",
    "            best_rmse_train = rmse_train\n",
    "            best_pearson_r = r_test\n",
    "            best_test_width = avg_width_test\n",
    "\n",
    "            best_coverage_test = coverage_test    \n",
    "            best_rmse_test = rmse_test\n",
    "            patience = 0\n",
    "            best_ensembles = initial_ensembles\n",
    "            \n",
    "        else:\n",
    "            patience = patience + 1\n",
    "            \n",
    "        print(\"Patience is\")\n",
    "        print(patience)\n",
    "        print('\\n')\n",
    "        \n",
    "        if (patience > threshold) | (i == (epochs-1)):\n",
    "            \n",
    "            # print()\n",
    "            # print(best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, flush = True)\n",
    "            # print(\"done for fold\" + str(idx), flush = True)\n",
    "            print(\"train_coverage\" + str(best_coverage_train), flush = True)\n",
    "            print(\"test_coverage\" + str(best_coverage_test), flush = True)\n",
    "            print(\"train_width\" + str(best_train_width), flush = True)\n",
    "            print(\"test_width\" + str(best_test_width), flush = True)\n",
    "            print(\"pearson\" + str(best_pearson_r), flush = True)\n",
    "            print(\"rmse_train\" + str(best_rmse_train), flush = True)\n",
    "            print(\"rmse_test\" + str(best_rmse_test), flush = True)\n",
    "            # print(\"smiles_weight_ci\" + str([best_li_smiles_weight, best_ui_smiles_weight]), flush = True)\n",
    "            \n",
    "            return [best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r, best_ensembles, [data1_test, data2_test, data3_test, data4_test, y_test]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11a8c623-2952-409f-a640-7d89cef6b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "909888fc-c2b2-49e9-b0f0-887c8fa4d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r, best_ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14658528-ea1a-4a6f-83bd-f708df0bcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 214.80967689764282 7.932344804868163 -0.12405247954207049\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 216.38486092869513 8.02200016317631 -0.1294488335318773\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 162.03073275722204 45.410152881494206 -0.007130355540009015\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.879 160.82394228366948 43.85133035506159 -0.03880815291567186\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8392 38.64757811566468 14.637175706044502 0.1879042851189838\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.834 39.05799049179966 14.735288883772501 0.20008145357638646\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7172 11.436306483325012 5.469319474302083 0.3236586503403656\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.695 11.478457620986527 5.741466237909003 0.3470986359392846\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.922 7.852548514610696 2.1860787693088852 0.6994021899439057\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.912 7.895594994096564 2.292408815805112 0.6898260384435413\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9416 6.395866297511332 1.5639536585357865 0.832512421992039\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.93 6.4216424484685986 1.6484838268443502 0.8212234035780662\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9516 6.486098919355064 1.4654726671745384 0.8547348784876085\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.933 6.528887775637546 1.576507571830037 0.837737077732763\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.95 6.430942501446309 1.4549395415643902 0.8567939381632402\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.933 6.490757302095577 1.557935988401033 0.8418431837605772\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9476 6.279897125258554 1.45375371294179 0.857056017041414\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.93 6.318580752503711 1.5672190646304969 0.8398043622196635\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9544 6.573970780920298 1.4477578303913925 0.8583190213444596\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.928 6.61688029904768 1.55798617225738 0.8419530500687871\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9456 6.296770938774139 1.4465386747238662 0.8586108131996134\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.929 6.338340614183751 1.5570312837167402 0.8420405668113876\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.954 6.566488704030036 1.44489531320587 0.8589268370418948\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.949 6.592920538084097 1.5525037254847338 0.8430608814852915\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.95 6.334723540234498 1.4469363701457303 0.8585868444677816\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.932 6.390820797362442 1.5558346852031928 0.8427190559867552\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9532 6.449210143630003 1.4398656639041774 0.8599550040700316\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.94 6.517523992770266 1.555055808555362 0.8425084169031636\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.956 6.513992974753345 1.4418531732907716 0.8595540351526301\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.942 6.551235598623886 1.5508370031592906 0.8435213862990518\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9496 6.4891638341502595 1.4404667266716489 0.8598325609925924\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.93 6.524053485795324 1.5508300493735434 0.8435084539461868\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.956 6.54386832576117 1.438103626717804 0.8603804332186581\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.941 6.583435381511404 1.54790728698988 0.8440639618497868\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9512 6.429281366732015 1.4422057426992878 0.8597160838264283\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.935 6.479560677126898 1.552445057936682 0.84313630808684\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9584 6.609745068454886 1.4363860294785311 0.8606902236680998\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.941 6.646074660283633 1.5483019611069906 0.844041947873472\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9604 6.675955588202591 1.4373922957275813 0.8604724664489982\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.94 6.706171371510412 1.550596563697487 0.8434994119901467\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "train_coverage0.9584\n",
      "test_coverage0.941\n",
      "train_width6.609745068454886\n",
      "test_width6.646074660283633\n",
      "pearson0.844041947873472\n",
      "rmse_train1.4363860294785311\n",
      "rmse_test1.5483019611069906\n",
      "CPU times: user 14min 53s, sys: 9min 46s, total: 24min 40s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r, best_ensembles, test_items = get_results(idx = 0, var_weights = 1.0, var_weight_weights = 4.0, var_D = 1, inflation_factor =1, fudging_beta = beta(1,19), \n",
    "           fudging_var = 5e-3, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b087a38a-18f6-46d0-aa00-4c2a0baaf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_test, data2_test, data3_test, data4_test, y_test =  test_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9490af0c-5a1b-43fb-8431-b1282db34b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test, _, _, _, _ = get_predictions_test(data1_test, data2_test, data3_test, data4_test, best_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7779268c-ab61-4401-80a0-44538877c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_preds_test = preds_test.mean(0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35f093e5-520c-41f0-a675-01ac46f87a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, averaged_preds_test)\n",
    "plt.axline((0,0), slope = 1, c = \"black\")\n",
    "plt.xlabel(\"Ground Truth Values\")\n",
    "plt.ylabel(\"MEnKF-ANN Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b6dbeca-651e-4d31-89c0-c44e35b4270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c969db3-06fd-4a30-8f3e-1d1670a03aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = pd.DataFrame(items).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01f44639-4484-45c7-bd7c-7745ab18371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.columns = ['best_train_width', 'best_coverage_train', 'best_rmse_train', 'best_test_width', 'best_coverage_test', 'best_rmse_test', 'best_pearson_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ab228b9-c61a-46cb-aa57-7acf4da3b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = items_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "925c745c-7a4d-4d78-8f47-9a1d7e11a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.columns = [\"Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d93ed649-b0ba-445d-b28a-ffeb603dc960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_train_width</th>\n",
       "      <td>6.609745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_coverage_train</th>\n",
       "      <td>0.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_rmse_train</th>\n",
       "      <td>1.436386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_test_width</th>\n",
       "      <td>6.646075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_coverage_test</th>\n",
       "      <td>0.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_rmse_test</th>\n",
       "      <td>1.548302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_pearson_r</th>\n",
       "      <td>0.844042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Value\n",
       "best_train_width     6.609745\n",
       "best_coverage_train  0.958400\n",
       "best_rmse_train      1.436386\n",
       "best_test_width      6.646075\n",
       "best_coverage_test   0.941000\n",
       "best_rmse_test       1.548302\n",
       "best_pearson_r       0.844042"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c743cac6-4f17-49ab-9ad0-f35b685d22f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 1000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ce0a569-aed6-42db-afa8-83819760c033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = random.sample(range(y_test.shape[0]), k = 16)\n",
    "fig, axs = plt.subplots(8, 2,figsize=(15, 15))\n",
    "axs = axs.ravel()\n",
    "for idx, i in enumerate(random_idx):\n",
    "    # print(counter)\n",
    "    truth = y_test[i,:]\n",
    "    preds = preds_test[:, i]\n",
    "    percts = np.percentile(preds, axis = 0, q = (2.5, 97.5))\n",
    "    lis = percts[0]\n",
    "    uis = percts[1]\n",
    "    \n",
    "    \n",
    "    axs[idx].hist(preds)\n",
    "    axs[idx].axvline(truth, color='green', linewidth=2)\n",
    "    axs[idx].axvline(lis, color='red', linewidth=2)\n",
    "    axs[idx].axvline(uis, color='red', linewidth=2)\n",
    "\n",
    "# plt.title\n",
    "fig.savefig('gcn_cdr_pred_intervals.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31471813-3497-4224-acf3-2bd150a35690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26cbcc74-a96c-45c2-9e18-c15480f2be2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9ecd4-18ce-4ef4-83c8-dded03b1f0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 249.2967039037332 6.418029028483904 0.021987473481763945\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 250.73887640829585 6.442939837854665 0.03740914379815247\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 121.49223032053712 13.034034956182047 -0.31561128475465117\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 122.34419483462666 13.044216567071615 -0.30085394947854593\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8704 33.07431268431803 10.843763855351462 -0.2943905735257198\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.878 33.40172838902654 10.963602721630153 -0.2732901865163432\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5932 8.403084523060176 4.937197634169148 0.09072665072144044\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.583 8.434642538149125 5.004458329956511 0.10246401483785664\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6836 4.6276909837773 2.242192217728814 0.6321417540203222\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.676 4.671332295680967 2.26785775825818 0.635533979902377\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.78 3.7434190684311384 1.510694033951927 0.8442317877559832\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.767 3.792786775035943 1.590956334938409 0.8347800914069834\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.7747490993324675 1.4188413931488941 0.8632184571154703\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.8 3.8208326228114595 1.5390697077175772 0.844905117484829\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8056 3.667200023726252 1.4133327937854336 0.8643992397713096\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.79 3.695138729890124 1.5377892533795472 0.845276207882591\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.822 3.8860746893496487 1.4109273643777098 0.8648072666740093\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.9348034632573006 1.5374328652695235 0.8451391449648218\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8284 3.909076452738436 1.4097115929111577 0.8650703075088036\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.808 3.9524405918601895 1.5349522496439743 0.8457054346892107\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8228 3.849855271836176 1.409559747976127 0.8650901486330105\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.808 3.8804497770381072 1.5401412435668405 0.8446226685497561\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8364 3.9906586703744744 1.4101625429987517 0.864983691210768\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.827 4.039895557577829 1.543078964233859 0.8440455674691569\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8168 3.853455147874116 1.4083953852761808 0.8653640505793346\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.809 3.89254148403433 1.5377410299617527 0.8451261261067367\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.834 3.9552666013029114 1.4084537199522564 0.8653186752265608\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.819 3.982119404650407 1.5348880660367037 0.8457656448978774\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.836 3.949090795602408 1.4074000656053731 0.8655402890640763\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.819 3.9780352514581208 1.538153638036363 0.845054647670558\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8364 3.9877335061776304 1.4079665211632943 0.8654542526849501\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.825 4.014600127817794 1.53679258169927 0.845533446909553\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.84 4.028915207563322 1.4073345098214265 0.8655813242327992\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.839 4.071387408268734 1.5369617351350033 0.8455046330577277\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8356 4.0329470341672815 1.4082263496997705 0.8653893060032587\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.828 4.07018132301638 1.5373520254341486 0.8452538751848359\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8448 4.062178116438578 1.4080003356836324 0.8654654928306961\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.836 4.104970003670888 1.5448456159639359 0.8436160987285285\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8428 4.04330824935398 1.4068239974865409 0.8656930679304135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.834 4.078067280167251 1.5366495126355146 0.8455627889721435\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.8428\n",
      "test_coverage0.834\n",
      "train_width4.04330824935398\n",
      "test_width4.078067280167251\n",
      "pearson0.8455627889721435\n",
      "rmse_train1.4068239974865409\n",
      "rmse_test1.5366495126355146\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 258.65612764074257 11.25690885878955 0.10614787784036837\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 261.58141339722846 11.555131900038921 0.019969362995128716\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 216.2188682797431 42.65519793389336 -0.127839717348533\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 219.51814687293913 44.801202424831295 -0.18261706719889675\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5828 62.07315124588366 37.57214799924753 -0.10348642233607\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.601 62.36203643814459 36.90158288666339 -0.18304622294568246\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5352 24.257826259896312 16.39050925124528 -0.12290562486501666\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.555 24.527859441382635 16.283423189928698 -0.2136859791540318\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7844 18.602193352480494 7.490321812758041 0.04292052631973572\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.802 18.810337847612725 7.453241742744549 0.0017193568715574237\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 16.435491331472537 2.0750788177347017 0.7358964434357708\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 16.67959804971416 2.102704691730842 0.725308729237696\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.926166867867735 1.5998474658788768 0.8373166422969527\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 16.07297486637632 1.594684317022594 0.8412398584687477\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.285275904360024 1.5090450229726533 0.8489948292774963\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 15.444399484690384 1.5812543844740807 0.8394458645454407\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 15.101298398205154 1.52059255234178 0.8451535055226483\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 15.197797433152997 1.557444927159746 0.8399955863234295\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 15.861538688097076 1.5176060000928595 0.845656648476819\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 16.009926932358695 1.5438793361596028 0.8420228591670029\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 15.550566803250934 1.4894048787993976 0.8526252190762912\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 15.68526208294625 1.5751008772754125 0.838752119929267\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.311814360347865 1.4919194535873042 0.8530481022171398\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 15.48570288331111 1.545337196464952 0.8457614035127179\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 14.708689835828874 1.505540720010246 0.8484825202500553\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 14.852320799335414 1.5619546591569042 0.8387085434155543\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 14.100249637486657 1.480725051189427 0.8537617210173675\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 14.261717697694186 1.5445659927557982 0.842849819477687\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 14.350246654807 1.5024060078771355 0.8492793804055899\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 14.50166331073749 1.5631384204688512 0.8374649259129586\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9988 13.810865344093749 1.4893754183638306 0.851833871203531\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 13.92995578973645 1.5530965993337795 0.8403343958427114\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 13.88552306790292 1.4824638795537648 0.853491286758691\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 14.005951165775674 1.533315748507612 0.8453980177245138\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9988 14.00744222149644 1.4877352834412034 0.8522241530753873\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 14.163324608194175 1.5288988052898775 0.845835980386188\n",
      "Patience is\n",
      "4\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 14.049116545149259 1.4918200994109891 0.8517027530739157\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 14.162200768771324 1.5537781638020978 0.8395867259153081\n",
      "Patience is\n",
      "5\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 14.130949513183438 1.4935330604596802 0.8510641880496169\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 14.254145066701716 1.5493761620069175 0.8407081085718074\n",
      "Patience is\n",
      "6\n",
      "\n",
      "\n",
      "train_coverage0.9992\n",
      "test_coverage0.998\n",
      "train_width14.100249637486657\n",
      "test_width14.261717697694186\n",
      "pearson0.842849819477687\n",
      "rmse_train1.480725051189427\n",
      "rmse_test1.5445659927557982\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 285.1702537261598 7.196805723280597 0.32025745519302523\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 281.16118024126683 7.2296110482965386 0.2731932171543805\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 112.66622961863513 9.268480785411148 -0.025088082601412934\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 111.20089483780546 9.579182346979586 -0.10536708953134777\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9048 24.233255645158863 6.317586439452775 0.0866185688618637\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.883 24.06080574496467 6.572060202914531 0.027219715203303425\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6028 6.386753123951444 3.593684531140706 0.36031156466360165\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.567 6.30296277153188 3.7458027404526044 0.26196777470391125\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6532 3.47856572912596 1.8483195978615823 0.7857239037975332\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.628 3.449420846285291 1.8924808765953325 0.7350387659823546\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6968 3.0347505569508058 1.5273120189136833 0.8569075560987202\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.674 3.010549967256143 1.5608811939782092 0.8230722049210899\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.724 3.1582877208580014 1.4900412189158705 0.8637613188961833\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.708 3.1204044688418358 1.5288386671561165 0.8312341301331098\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7328 3.1587322330428873 1.4855840805904257 0.8645258444708539\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.715 3.124973349565094 1.5228897126301333 0.8334146192171685\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.732 3.189267534761389 1.4830446096789933 0.8650394438166656\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.719 3.1612235582817227 1.514960142371936 0.8348116299770423\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7236 3.106523501196564 1.481392217744095 0.8653550338004281\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.711 3.0840133677006647 1.5165284863124662 0.8348789617548091\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7324 3.1555758743476066 1.4812842791573637 0.8653964738936512\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.72 3.1300686259530552 1.518689698741745 0.8351610043736948\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7364 3.1638153228266477 1.4812298464649625 0.8653855908971015\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.718 3.1219706848836237 1.516058972644021 0.8353104091791285\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7488 3.223903630476978 1.4801971416387025 0.8656176377856935\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.723 3.1846651651256974 1.517200675543315 0.8352970382306738\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7468 3.2255198496508894 1.4803155789800209 0.8655748281668998\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.716 3.199088032254356 1.5172741868471116 0.8348528472256496\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7544 3.3027475065810723 1.4797196881477606 0.8656743282107553\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.733 3.2781243261552526 1.5146570465575502 0.8352444097765848\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7436 3.217079242071431 1.47992479761909 0.8656480814008971\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.724 3.181807820209241 1.511345344953153 0.83562284384941\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7448 3.272764129729449 1.480289238188038 0.8655730647474321\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.724 3.2506130942486218 1.5178371639531565 0.8350320439480989\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7504 3.2898268754217455 1.47973267135236 0.8657186726156619\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.737 3.253541794962368 1.5111823007938674 0.8352325489256809\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7484 3.246644910516405 1.4796592952933332 0.8656913310044457\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.735 3.2153312596774892 1.5157768332648627 0.8353153026532063\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7428 3.225293450547045 1.4796135871805018 0.8657053505542852\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.719 3.179251877271742 1.5134310664843784 0.8355952251398312\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.7428\n",
      "test_coverage0.719\n",
      "train_width3.225293450547045\n",
      "test_width3.179251877271742\n",
      "pearson0.8355952251398312\n",
      "rmse_train1.4796135871805018\n",
      "rmse_test1.5134310664843784\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 211.27977493149106 6.661791520788363 0.052075992280336485\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 212.39940304063623 6.526571359845551 0.05329572195620114\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 73.94949728395399 7.966628715981201 0.18209982920482826\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 74.11465117027211 7.982703896625254 0.18740011985072577\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7368 27.525377229521993 12.009504555990905 0.03452181537250976\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.72 27.75518318853049 12.416408580807394 0.02110405173406043\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5468 8.487315603380232 5.9500640029755125 0.29837620898189066\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.538 8.478380504501715 5.976264174472132 0.29148531568081487\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.642 4.4401618302338735 2.5051594622291566 0.589583138994173\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.648 4.452769811509422 2.48491224644229 0.5943728567917499\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8168 4.028403569205654 1.5477194722885383 0.8349413712372198\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.8 4.034130792569459 1.5442836084701645 0.8358644337806886\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8316 3.9863938641523333 1.4612696081007213 0.8538050325317768\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.813 3.99131642299045 1.465397046924934 0.8525813813633214\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8248 3.8797777232511566 1.4514437722619606 0.8559373659319462\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.808 3.889263827303415 1.456888572720387 0.8544664013116406\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8196 3.8791167072253083 1.4502600864139061 0.856218856258995\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.803 3.8848618834184254 1.458619490050326 0.854735502460076\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8256 3.9614102231296755 1.4473623151256485 0.8567877599021576\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.813 3.957186732069393 1.4575323276203813 0.8547440628558091\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.836 4.029189068925595 1.4459421089928204 0.8571158756149964\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.821 4.049699218657431 1.45883405464757 0.8542453840611268\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8328 4.000098813325468 1.4460218607653796 0.857103149823476\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.814 3.9976043359171016 1.4568747681337317 0.8548620127869899\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8336 4.020808658223334 1.446022562267509 0.8572059752606903\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.82 4.018118385902286 1.4610310122017458 0.8546029978050103\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8356 3.9954996712946493 1.4461607533144112 0.8570516381650675\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.826 4.000407800267117 1.4620422313548214 0.8539459363577627\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8412 4.019245711478079 1.4448287781680986 0.8573592951267748\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.82 4.013379285480509 1.4590329962153294 0.8545496486138746\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8332 4.0436696049963805 1.4450382533770836 0.8572890331448936\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.822 4.055444992985025 1.4592180383937812 0.8544005918605715\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8344 4.049793267309514 1.4454202032346732 0.8572378722302123\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.829 4.07196171289967 1.4593190053574856 0.8546381485500848\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8336 4.011156737512262 1.4442599942409007 0.8574458767017511\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.817 4.015443678018182 1.4570403542165595 0.8549583363668362\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8292 3.964840770312087 1.4443581133715697 0.8574166839609515\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.811 3.9646246819747155 1.4604231803970011 0.85410852067026\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8404 4.066812354993781 1.4444719342364525 0.8574726183161558\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.823 4.042462622461069 1.4603007591887096 0.8539364322365188\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage0.8336\n",
      "test_coverage0.817\n",
      "train_width4.011156737512262\n",
      "test_width4.015443678018182\n",
      "pearson0.8549583363668362\n",
      "rmse_train1.4442599942409007\n",
      "rmse_test1.4570403542165595\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 194.0327370859694 6.484520677663326 0.020620026206949447\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 193.39880984935988 6.613552546148203 -0.05874676364671967\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 80.50532970823653 7.286800962329959 -0.045389600870139615\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 80.12622463126475 7.530559038100438 -0.09169986546978269\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.856 25.58999567829519 8.297425417907073 0.003991922458866508\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.868 25.498404892895163 8.154761937194406 -0.04064715067997984\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5816 7.874806379097338 4.531301835545347 0.17692270591141257\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.559 7.902721017249295 4.494681121913934 0.1467125975374979\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8156 5.364048512887858 1.9018247277459486 0.7417860093075387\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.821 5.363036014248641 1.9771252580043035 0.7473421150447427\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.832 4.500573768890763 1.5670440321780454 0.8310983406317433\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.821 4.500149547137178 1.642130565815247 0.8328250583739639\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8588 4.514279011042724 1.5030774981386983 0.8453750735471838\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.84 4.5269102676560085 1.5507093781296117 0.8519935736912494\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8736 4.821913004628244 1.4825465406245872 0.8501455065474783\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.858 4.808270998964477 1.5406196771859102 0.8543829098747839\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8912 5.204299351460456 1.4750837415269529 0.8515791701785904\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.883 5.222927325189486 1.5377728203550172 0.8547236357728207\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8944 5.116170274398809 1.4733809754088443 0.8519461354597326\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.877 5.123881555320404 1.5402672044457395 0.8542303888389761\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8984 5.221966474959976 1.4710250731360333 0.852445053532774\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.89 5.206495997655799 1.534904157516427 0.8552600231447198\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8896 5.067797200914728 1.471720999310659 0.852306464111643\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.882 5.057305761242984 1.5294312405015351 0.8564032252745961\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8924 5.275692233502152 1.4718171857176876 0.852284582652438\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.879 5.265567669151606 1.5400991737916827 0.8542579657697285\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8924 5.107356639741303 1.469949155010332 0.8526878047927775\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.876 5.100617206129941 1.5328276883619882 0.85567969201892\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.89 5.13859854480733 1.47028195845048 0.8526052437362407\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.881 5.137686852042927 1.5354939192612271 0.8551431888250083\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.894 5.127970561420388 1.469702644178756 0.8527488634569718\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.882 5.099797513352938 1.539373060856822 0.8543460806593693\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8892 4.971940739208886 1.4710100904883607 0.8525671519996855\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.87 4.954094681062637 1.5340650485357337 0.8556313990298967\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8872 5.030985920492433 1.4693613103616883 0.8528188317687104\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.87 4.9979091774489115 1.530875544140395 0.8560904539021856\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.898 5.370941015084881 1.4734887632204505 0.8520648858177563\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.896 5.360351232617637 1.5438225425179317 0.8537370339013262\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.89 5.208877445928808 1.469658843279569 0.8527799586561388\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 5.15997058924251 1.5331516022389522 0.8556045280726536\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage0.8872\n",
      "test_coverage0.87\n",
      "train_width5.030985920492433\n",
      "test_width4.9979091774489115\n",
      "pearson0.8560904539021856\n",
      "rmse_train1.4693613103616883\n",
      "rmse_test1.530875544140395\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 230.19674594577063 6.735601380147021 -0.0894380887930942\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 229.0124180762741 6.749605885771004 -0.048817286588837515\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 136.46103042978012 18.035061771557544 0.09436827113402896\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 134.24625991036697 17.981749798248106 0.1462004390557148\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.906 44.770810617311476 12.920545983704987 0.024568787654056817\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.899 44.133164080838355 12.905149977265145 0.03849431415912308\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7972 14.365403183691932 5.755705265396693 0.27207892773349335\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.801 14.195193019361723 5.654830229925405 0.23931620961466693\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9344 8.970772979187098 2.3385693369419402 0.6566339640323645\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.933 8.900564637736927 2.330349883646003 0.6389194334453734\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9764 8.500447772861293 1.6497321211284524 0.8176748827216618\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.972 8.450467869742765 1.6795217536853797 0.7974499501110469\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9808 8.439777677260281 1.5311701594064087 0.8455894991346657\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.98 8.377411667338277 1.584352358370973 0.8225303444555079\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9784 8.31128944561577 1.5100995490008582 0.8500738730891809\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.972 8.208999144005405 1.569354867604259 0.8264083472417799\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9784 8.361218095513923 1.5173503337304475 0.8505380247972182\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.978 8.299687146857476 1.5714525056315236 0.8244276036030642\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9792 8.264271449581472 1.5047372506024466 0.8515164025114578\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.973 8.218527232726677 1.5558951185505314 0.8288162498173702\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9808 8.434398335775825 1.4897348695578139 0.85438449498935\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.979 8.38167631441224 1.5397792580826521 0.8328775348420105\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9828 8.564060507255645 1.4897576427247365 0.854596863934359\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.978 8.52206175275427 1.5442378498168425 0.8314205698175132\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9832 8.499465208573357 1.4842345863724455 0.8554417132768125\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.973 8.402259772611961 1.5425439461308381 0.8326500922751566\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9804 8.162673472088116 1.4859593713622017 0.8550527419952404\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.974 8.075317871900031 1.5486684062461367 0.8316428794474249\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9836 8.409552658342259 1.496371582640073 0.8529253636969983\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.973 8.368569810874924 1.5637397565203197 0.8284741268534536\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9828 8.604959630654244 1.4901033246790367 0.8542669929254231\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.98 8.536215570460064 1.5421421632293844 0.8340577789723019\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9844 8.596175570831344 1.4908676778420888 0.8540513182985884\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.981 8.543274404083421 1.5425455673873738 0.8334991116777122\n",
      "Patience is\n",
      "4\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9804 8.226952022496139 1.4860217241577125 0.8551195158747265\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.972 8.161273056531432 1.5464042883100724 0.8320298520805104\n",
      "Patience is\n",
      "5\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9848 8.4525742858724 1.486845558313412 0.8551166597261639\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.98 8.364944202555902 1.5343816540515447 0.836135136890152\n",
      "Patience is\n",
      "6\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.98 8.386614214349565 1.4873824199160308 0.854870010088141\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.977 8.361564691599881 1.533353857629424 0.8344689079035802\n",
      "Patience is\n",
      "7\n",
      "\n",
      "\n",
      "train_coverage0.9832\n",
      "test_coverage0.973\n",
      "train_width8.499465208573357\n",
      "test_width8.402259772611961\n",
      "pearson0.8326500922751566\n",
      "rmse_train1.4842345863724455\n",
      "rmse_test1.5425439461308381\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 317.50672631467074 11.13243780565879 0.05694792587507048\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 317.18015416049303 10.80859247022668 0.0611682627655792\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 218.30824340637588 29.83823603230158 -0.009260788439001423\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 216.2907485478329 28.638244830100838 0.009522170244027068\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5596 89.77856537570216 54.05244228689712 0.03827110936531494\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.568 89.16354392151297 53.34549098380412 0.06714750601055723\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5768 29.01554030984031 18.097515546791797 0.18333164914475578\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.546 28.83696240860229 18.138612149322427 0.22337253004848084\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9628 22.747928042783663 5.31203310018065 0.498861013483238\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.974 22.626053911584364 5.114274329000233 0.5262376118082912\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.242742887180288 1.7693611496652972 0.7900336283311759\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.160634321622382 1.7824135925110522 0.7905695048949499\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 19.461146233853434 1.555675658724331 0.8357331530504476\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 19.36560382347326 1.6236060344382939 0.8231007693794553\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.734136870891696 1.6722049748371515 0.8073196201660412\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.66452079969689 1.7629277034873372 0.7881328726045329\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.438295250387544 1.5387623354470226 0.8389957262328197\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.354596804731422 1.6517971450990623 0.8155748189719003\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.874085923962777 1.5693907718935978 0.8350065327443245\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.730765715228358 1.6768407689272529 0.8117322836819061\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.887717809643537 1.5292685793283833 0.842500547694504\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.73622694382947 1.6426415283441709 0.8203313577948942\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 21.306404239516095 1.5089806373108143 0.8457664629729589\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 21.254639302418674 1.63647419467365 0.8198315322264206\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.70742719716322 1.5037555178001283 0.8476346642661594\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.621026297270838 1.6152763768873184 0.8247997131076638\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 21.82342516690075 1.493736193287919 0.8501626967551139\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 21.772288257865814 1.5956028682314547 0.8300642792427809\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 21.67746290116084 1.4975965245514542 0.8484886322677913\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 21.63059984225066 1.5955021075018867 0.8297536510628144\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.87679892475121 1.452268130740042 0.8590552312345593\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.735821902220625 1.5327754384416363 0.8444387548470415\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 21.07063770819579 1.4649076359122335 0.8564520637892823\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.981864440956766 1.5750773307123642 0.8350036787813674\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.854091092827304 1.439912372900077 0.8605584438944401\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.71547618168569 1.539620440509275 0.8420823392266965\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.944056385944446 1.4629599031503984 0.856285544178931\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 20.86836660397195 1.5735345439530488 0.835493447978038\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 19.877701913103305 1.458876398501696 0.8565590803422636\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 19.78453754182216 1.55444661374697 0.8388108293344727\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage1.0\n",
      "test_coverage0.999\n",
      "train_width20.854091092827304\n",
      "test_width20.71547618168569\n",
      "pearson0.8420823392266965\n",
      "rmse_train1.439912372900077\n",
      "rmse_test1.539620440509275\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 239.87157318798526 8.199741126921216 -0.058796916774217105\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 239.21907115671485 7.965733809580262 -0.022367815554991486\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 122.63282673091405 18.04164619027711 0.0037971568894763393\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 122.18924614057397 17.886244771568443 0.007543396200502557\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.834 25.697391330797497 9.797981756363367 0.08400030292370059\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.841 25.666625511853994 9.576477144695518 0.06356645247697072\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6332 9.224892027882404 5.135705612817427 0.20874542729639603\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.626 9.205242084006114 5.12532972443392 0.2206734752971402\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6152 4.215160581275633 2.353260958007662 0.5941622923930726\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.607 4.1918285824341455 2.35780608279497 0.588309806458829\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6588 3.2603496431519283 1.7404749529711911 0.8013532504219834\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.623 3.250847070635592 1.8108739848747282 0.7787903203129188\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7632 3.537279476549133 1.4859751758697752 0.8562448285079179\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.718 3.5245304003428615 1.5855089622870437 0.8327914638173355\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.796 3.745375373340426 1.456264874756192 0.8623626056649318\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.771 3.720922967290783 1.5537244984919558 0.8401693664375802\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.7778140294614104 1.4487356620857414 0.8638893418503691\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.771 3.7576909272411054 1.5446486396926553 0.8420989020076758\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.823685112302218 1.4458392305000505 0.8645155872581752\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.774 3.829799006093545 1.549727119021714 0.8410717541543806\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8144 3.8476687401047793 1.443757203324773 0.8648517402301686\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.78 3.8464051654921216 1.545893636188242 0.841830066266186\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8164 3.914308105774474 1.442781470354249 0.8651125140520933\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.782 3.91294356702212 1.547694182431707 0.8415239055418031\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8188 3.9701393791021897 1.4428615038411174 0.8651777701311552\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.787 3.9644712981435943 1.5457425407484786 0.8421225959441324\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8132 3.9129977168643606 1.4420605258197903 0.8652069669330903\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.788 3.9078277032236266 1.5503390105034522 0.8408518584158451\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8192 3.894304332641088 1.4407576840907208 0.8654584005346688\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.783 3.891989209650338 1.541171828810848 0.8428887633397945\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8056 3.8316898590198805 1.4411731484516161 0.8653769567393135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.773 3.8286255827290017 1.5444956624324506 0.8421374995748635\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.802 3.7975518228051985 1.4400995553280433 0.8655840719747742\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.755 3.807853863166781 1.5444770333296634 0.8421617061245517\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8084 3.8240733148645747 1.4396365980374521 0.8656822331796188\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.773 3.810805184587871 1.543282432904452 0.8424562965854618\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8068 3.844074747542906 1.4397893892719824 0.8657236154546948\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.776 3.8423364063046783 1.5464499869405628 0.8417118221820642\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.808 3.8074051461428704 1.4396525730821925 0.8656862446606176\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.779 3.816849309901756 1.5425278853315094 0.8425745740344783\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage0.8084\n",
      "test_coverage0.773\n",
      "train_width3.8240733148645747\n",
      "test_width3.810805184587871\n",
      "pearson0.8424562965854618\n",
      "rmse_train1.4396365980374521\n",
      "rmse_test1.543282432904452\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 258.339580817807 8.380489488602427 -0.048668174337211115\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 258.39653641807246 8.18698551671475 -0.006459089477208044\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 139.37652338791128 17.92373648221944 0.09840437622964997\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 139.3693101005204 18.088216834496116 0.10439635889690718\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8828 34.29576297379269 11.471786060276779 -0.3050260361067615\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.889 34.322209433371306 11.15583760058127 -0.2780879803479573\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.648 12.4146524291974 6.993352455590589 -0.05646695097574473\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.637 12.33408718309636 6.905653988053825 -0.031149405755328367\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7284 6.538680897134386 3.1756143404091195 0.3574211547211677\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.703 6.485894936129112 3.114179546340119 0.3752882077494307\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8268 4.663003612113716 1.7678814167508545 0.7915872789005052\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.79 4.62107809891071 1.8006738659172163 0.7861331491928489\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8988 5.077049841116356 1.4914385996973798 0.8571783125119338\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.868 5.021711748832224 1.55737219802701 0.8447116762395349\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.91 5.128621021432812 1.468293690552134 0.8607895469809549\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.891 5.077113700802334 1.5384395060205032 0.8475085079119411\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9056 5.135415346961587 1.4567360452947162 0.863210621509718\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.876 5.097761105147368 1.5388694251866621 0.8475848962722983\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9172 5.240757316117979 1.454659728885218 0.8635443561880551\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.882 5.186042675017012 1.5429440889285109 0.8467465518182365\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9064 5.117761194799096 1.4523646590193577 0.864010845716724\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.877 5.064600756436745 1.5434536093329352 0.8466542306131499\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9004 4.96345859594132 1.4506180048871515 0.8643795893073155\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.879 4.940794876381295 1.5470687941181005 0.8457444989427894\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.896 4.940612714455983 1.4530227550609693 0.8639053573235047\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 4.903186154745106 1.5453264363703239 0.8463025410665882\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8972 4.932659227189077 1.4496410487660258 0.8645598869420523\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.87 4.892637009463362 1.5438909118789699 0.8465539329417444\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8828 4.684119256410274 1.448308971953895 0.864828928360625\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.86 4.636542079842122 1.5481502155493203 0.8457375826098624\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8832 4.699231453122687 1.4495623997532083 0.8645985975877701\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.854 4.647778887742416 1.5549722853148324 0.8443777344014378\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.88 4.682028002264464 1.4497550079813204 0.864593062495731\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.854 4.651644707073739 1.549963827376491 0.8453740241266066\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8956 4.846752304819345 1.4479911663497578 0.8649657283725976\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.867 4.812008491665599 1.5467581815319158 0.8463418857382937\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8796 4.699511714107908 1.4494196395153764 0.8647793453373447\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.857 4.655425028581404 1.5534697748280148 0.8446952809128302\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8824 4.702843934027162 1.4480344187337022 0.8648857562678728\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.849 4.649527167603719 1.5538419307742235 0.8445233708572343\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage0.8956\n",
      "test_coverage0.867\n",
      "train_width4.846752304819345\n",
      "test_width4.812008491665599\n",
      "pearson0.8463418857382937\n",
      "rmse_train1.4479911663497578\n",
      "rmse_test1.5467581815319158\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 231.44738879432418 6.615070755657357 0.031203622905937436\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 231.43005048515812 6.386377393346764 0.05288588407912969\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 121.07921300096777 14.713493705744 -0.12937804037950382\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 121.67337542186792 14.659264080931157 -0.10898904015061554\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6236 45.78165171999013 24.10257108846308 -0.16829287282895408\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.599 46.08290672882093 24.849784861049642 -0.20451987729538643\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5008 12.175802756594871 8.269845827744112 0.09116236131976777\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.482 12.186225814133959 8.405932423903714 0.07223282829378017\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7784 7.206467968527083 2.913835724939784 0.5825336980810786\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.768 7.230499256826153 3.004038254436494 0.5686834253451027\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9256 6.4923100057471546 1.676025433819358 0.8043141181072446\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.908 6.5112844579461635 1.7961229889220693 0.8012146403220974\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9536 6.685822633531134 1.5109954033380293 0.843980029229943\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.943 6.702261331185122 1.6231023427591287 0.8406017345368941\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.956 6.872747750980736 1.5005787248947215 0.8462306991402216\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.941 6.840791984021446 1.6057188766057888 0.8442188636212687\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9556 6.984215345382565 1.4962984359841522 0.847419175305258\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.947 6.992174960709275 1.5961903171958345 0.8466141029268429\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.964 7.078486375428567 1.4888616092608404 0.8489503178666041\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.951 7.088750389838903 1.5829767854731331 0.8490254171350623\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9572 6.815196128464934 1.484387393376529 0.8499142677739344\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.944 6.837411187672657 1.583995287686291 0.8489436474847564\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9692 7.400196001701259 1.4835477824899321 0.8500201489165132\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.961 7.43709941068387 1.5843624159633756 0.8487666628721426\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.968 7.297977594358599 1.485758683589984 0.8496030444732144\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.956 7.344093977840139 1.5908811471411364 0.8475777084184795\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9616 7.129609041939004 1.4816374064964362 0.8509133805690494\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.95 7.179645795565401 1.581474220666085 0.8501886598843685\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9644 7.0596193961482 1.4767729765185058 0.85149207059359\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.949 7.093057583805015 1.5739318870863859 0.8508538129146417\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.96 7.054087279959148 1.4813313616926742 0.8505440697212254\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.949 7.060640600812479 1.586252132433378 0.8485274215234687\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9548 6.68320254872641 1.4795912419699278 0.8509916670490265\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.942 6.709236624788269 1.5761181694888324 0.8507791776081589\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9528 6.661576369845403 1.479181342031944 0.8509413654798403\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.944 6.670254466275008 1.5741960155545982 0.8508214308026334\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9544 6.581346475667492 1.4772215218833666 0.8515767532208796\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.939 6.609024020996753 1.5691903911986964 0.8520338442822539\n",
      "Patience is\n",
      "4\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9556 6.623581348149737 1.478329618955603 0.851148291830867\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.942 6.638989276409594 1.5668882914865088 0.8523962428477003\n",
      "Patience is\n",
      "5\n",
      "\n",
      "\n",
      "train_coverage0.9644\n",
      "test_coverage0.949\n",
      "train_width7.0596193961482\n",
      "test_width7.093057583805015\n",
      "pearson0.8508538129146417\n",
      "rmse_train1.4767729765185058\n",
      "rmse_test1.5739318870863859\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 268.144420143958 11.570781311375889 -0.10646369183507265\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 270.22660823112886 12.227428499927628 -0.1397499661460038\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 93.06478918521614 10.199984652291322 0.2319375402666516\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 93.61594784693818 10.321357410845563 0.2397368443318233\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8612 31.67363970400026 10.941361876390323 0.2372566884798601\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.87 31.749522386539688 10.701654462538267 0.21442605517110272\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5648 6.982704251323904 4.439236656071422 0.4503467059643592\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.577 6.960122863527046 4.377626802373585 0.4043596495429761\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.662 3.699162596527105 1.9916725808202773 0.7371570711307976\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.623 3.6808232603426334 2.074654264738666 0.7127053052148027\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.692 2.9578671455929957 1.5259157301619484 0.8361268037499177\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.652 2.970054006479451 1.5912364271025907 0.819192906723846\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6952 2.831692053931816 1.448631401414942 0.8541142109231281\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.656 2.8408204881618504 1.526768802429534 0.8346530255638516\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7128 2.904640608066011 1.4402275002495613 0.8555762973218376\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.669 2.925183437981769 1.5182932412216934 0.837287295092676\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7016 2.822908019471835 1.4375013464166917 0.8561258003699397\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.666 2.8413732890558223 1.5144686861365295 0.8381309592967815\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6972 2.8586960319215278 1.4379545146982189 0.8561397004375868\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.675 2.8778432179547533 1.5149875075939903 0.8385855515254005\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.702 2.855865396257343 1.435322430285762 0.856679198271062\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.674 2.8785782829568496 1.5131752245294672 0.8388094442317873\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7168 2.9167287569259783 1.434622385220133 0.856752255966555\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.68 2.9271619313453066 1.5100976158041681 0.8391526917488746\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7064 2.8872005280828903 1.4345353457026369 0.8567827215273146\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.665 2.8834335558995554 1.5107610991096299 0.8389433336799864\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7044 2.8480542113744027 1.4341138576235444 0.8568725099893696\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.668 2.8603947653699646 1.5123472145617 0.838540730983664\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7108 2.8941475181427174 1.4339581474184202 0.8569791705879459\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.671 2.912214726194751 1.5067279041339583 0.8397073682516623\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.704 2.857971921969045 1.4341515486338794 0.857018420796281\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.668 2.8634972177178453 1.5141296099506076 0.8388735263771054\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7032 2.84386930524765 1.4329956660189171 0.8571029528884032\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.66 2.846531018157023 1.5144589651866522 0.8382198803642629\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7096 2.857091644908828 1.4334707799428414 0.85704300308799\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.664 2.8857232010927483 1.51520012349098 0.8382708447935407\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6996 2.838894074842354 1.4332960429108073 0.8570932153871452\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.664 2.8436985447905 1.507808581106728 0.8393807199139025\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.704 2.858129524350966 1.4324550680122399 0.8572131396812135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.666 2.873503096500385 1.5111637711119275 0.8387967480485646\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.704\n",
      "test_coverage0.666\n",
      "train_width2.858129524350966\n",
      "test_width2.873503096500385\n",
      "pearson0.8387967480485646\n",
      "rmse_train1.4324550680122399\n",
      "rmse_test1.5111637711119275\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 293.3694918642567 7.673028203198952 -0.14622745915433652\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 290.71986929444734 7.502419000344067 -0.168912570244567\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9964 119.40569087700118 18.692790810709745 -0.24366211061976026\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 119.16756714984952 19.425706097909387 -0.2681366810462303\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8148 46.296755954782526 16.326830201548695 -0.24820914268403854\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.821 46.19259828979766 16.278644927870165 -0.1960326899409212\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6912 15.68582532776118 7.466511725287948 0.12389398490857877\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.669 15.623478132989273 7.600997480310405 0.147254783437796\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9896 13.635106553798641 2.635168910074103 0.6289606546878047\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.983 13.554352798965978 2.6162974726151114 0.6247872622399699\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 11.90786398072678 1.6690333338550627 0.7990829824947595\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.995 11.831030009267241 1.6874692634835884 0.7875510240259603\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9952 11.869041926115257 1.568648626025356 0.8260498419084346\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 11.806580865834599 1.590094424392347 0.8164497111641384\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9968 12.201821740991436 1.5569825418990848 0.8290247777192699\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 12.14056564541559 1.5758243328676749 0.8190656339367878\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 11.912094349320858 1.552410104079096 0.8286299368417221\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 11.813504916964845 1.5674889147071638 0.8200209859121587\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9976 12.21969891516931 1.5124183625868943 0.8383701724636865\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.995 12.118084014013457 1.54713627350988 0.8263279656888531\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9976 12.32606494771283 1.5063430423873696 0.8406928724779387\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 12.259648985149223 1.5393558374442646 0.8294679304303261\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 11.897061599211655 1.5036282396226075 0.8405945659609031\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 11.845908209696256 1.5281908131506967 0.8308509374139295\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9964 12.334273005091935 1.4853093792839176 0.8444882523337865\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 12.212890862027011 1.5086818735026366 0.8349968827334839\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9956 11.785494344201242 1.4899459709725442 0.843369873976873\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 11.680869930197044 1.5263954984569719 0.8309856432020662\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9976 12.52627209349423 1.4789705302143485 0.8458610522399116\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 12.39085177934168 1.5148369629724368 0.8337103506562549\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9972 12.185092228936671 1.4736138164796122 0.8471583673010398\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 12.12103217656499 1.5200983730819642 0.8329789785420776\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9968 12.577028074362898 1.4791209150848386 0.846134438958288\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 12.44748680876226 1.5109910493213483 0.8357257749464687\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 12.440886107338079 1.4810706808480256 0.8461309756429237\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.996 12.330925487438773 1.5185922003287704 0.8342645572690386\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 12.637710323991893 1.4686136145259931 0.8482880527393988\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 12.557542862451166 1.5192893065838196 0.8333206684751164\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9976 12.765943932678493 1.4806202529080845 0.8459407844351039\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 12.687660655395016 1.513807675684716 0.834995442761183\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "train_coverage0.998\n",
      "test_coverage0.997\n",
      "train_width12.637710323991893\n",
      "test_width12.557542862451166\n",
      "pearson0.8333206684751164\n",
      "rmse_train1.4686136145259931\n",
      "rmse_test1.5192893065838196\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 298.5915880143292 8.679691916774987 -0.21011483779844\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 299.92672668205074 8.589539316719872 -0.16027343242034248\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 183.0804009966229 22.937790241870093 -0.066757399351848\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 185.4066710483347 23.924014865287145 -0.13278886945648302\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6312 69.49395078805887 32.6906630673449 0.4421588693097502\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.633 69.64163075268065 32.742116977661894 0.4874570833000513\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.716 20.533685232602252 8.986214973140525 0.38940582071221863\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.707 20.681953583547692 9.08760568685212 0.4083802511436398\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9776 18.875512118859497 3.846249807663625 0.4537150280977073\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.983 18.97398893573355 3.8071232319518504 0.45857884250663467\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.241716541714133 1.707322978329509 0.7942004058940073\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.38504859142335 1.7595361726505547 0.7845465087662171\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 16.25200963305803 1.7234445849134425 0.7895838823657829\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 16.414943032759098 1.796202542795393 0.7742482723574431\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.857113793429628 1.6888227474549675 0.7990882960025755\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 15.965618324053 1.7813415549302227 0.778466420851866\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9988 15.293222016201101 1.620661495350867 0.820575381138406\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 15.334098967333507 1.7136191512527439 0.7999266632679995\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 16.30657304965246 1.5613120236927764 0.8311854188448752\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 16.425206283684066 1.6461507216895777 0.814791389497994\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 16.690924137890995 1.5415366484106336 0.8359724159233117\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 16.848004513869963 1.628210297874639 0.818930083291197\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 16.203275145546428 1.5451910038780672 0.8349787123907771\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 16.329835121017407 1.6433683126820366 0.8155061788989602\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 14.838348192253141 1.5201090362090894 0.8413205229163122\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 14.988044289202579 1.6186177891809508 0.8215106860318538\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.411943028206602 1.514308555772782 0.8432041507181234\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 15.469510300593251 1.6190733370412027 0.8214514724525976\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 14.802138111251582 1.4843609256107804 0.8488688757164528\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 14.944401763521041 1.6047461475438483 0.8254410750957103\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 14.762388958829813 1.5083531485220212 0.8434969705523349\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 14.9106441562312 1.6238437471653127 0.820554074164092\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9988 15.593350671965014 1.5758312106190344 0.8289582649564353\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 15.654504674469635 1.687160016271283 0.80457145377458\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9992 15.43474043292228 1.5046856218041726 0.8444328033046742\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 15.570953747604936 1.6232010924004865 0.8202948446028754\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 15.246518646780316 1.47502552016515 0.8510122494302437\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 15.294865785471833 1.591030668173494 0.8278835878761006\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 14.952980621799512 1.4889476182814545 0.8484019000863876\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 15.103514440268588 1.5879824493568149 0.8299584084707786\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "train_coverage0.9984\n",
      "test_coverage0.999\n",
      "train_width15.246518646780316\n",
      "test_width15.294865785471833\n",
      "pearson0.8278835878761006\n",
      "rmse_train1.47502552016515\n",
      "rmse_test1.591030668173494\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 286.28630738115686 8.159299788552266 -0.19371490782737902\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 285.07605340818543 8.35344378339623 -0.2651383404755168\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 115.73662932388619 8.208090247178841 0.07183617793967116\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 115.16128544807992 8.315589931474037 0.060013711822712416\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9288 60.454949600379145 16.79752503223091 -0.2887030545047003\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.924 61.156195593806856 16.341706572214868 -0.26154265397018234\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9216 23.05760540487906 7.004065666278613 0.03772816925552705\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.935 23.184551401882516 6.909848783781199 0.10073072097600523\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9344 23.008498262409084 6.5801383966905895 0.13460218224952988\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.927 23.11743146828675 6.5967832366033905 0.042580870600598196\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 20.490512811911564 2.340703032468131 0.6363370977474316\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 20.630636051926587 2.347904013060651 0.6266848992892822\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 18.745965177280386 1.7158079147699679 0.8026783927114871\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 18.82622217129361 1.7525011910791715 0.7887513457112338\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9984 17.468656761292312 1.700222471325743 0.8136345947966898\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 17.511763121219477 1.7455184194191178 0.7952370037119659\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.378937098385197 1.5741967770599334 0.8373941008145712\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.490043414700377 1.6086503670036012 0.825649280254402\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.494918741422687 1.5356996824599707 0.845205993523241\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 17.633361574542818 1.5534866368894265 0.838388903761967\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 16.904460735835123 1.5339928317204798 0.8455367913178465\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.997 16.93908212166119 1.5627089532196226 0.8359385763614581\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.602030828669673 1.5403397181691694 0.8440817704810601\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 17.660341089461102 1.5621850286817605 0.836343595576794\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.660467827638804 1.5427360416788165 0.8447012686969504\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.81268922132326 1.5719053056982786 0.8339034582800733\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.507286853135266 1.5238167570492784 0.8480478284720959\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.63185805864919 1.545568421054238 0.8406916470326945\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.073214716522106 1.5276101826524326 0.8471013902294151\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 17.19755475387855 1.5442419987131548 0.8401813725257078\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.617887080370995 1.56767959326694 0.8386146832010632\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 17.68223568005695 1.5975176554735224 0.8275768184910997\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 16.979489569636407 1.5423227638307357 0.8451105696509761\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.999 17.17008205016983 1.574501084339017 0.835515436459652\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 17.28365041941139 1.5461794649775562 0.842874400734768\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 17.294111371392596 1.5777770521598742 0.8334376078013896\n",
      "Patience is\n",
      "4\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.1449875999026 1.5569906999683838 0.8405883500423967\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 17.242739616978874 1.581507375957726 0.831464056045023\n",
      "Patience is\n",
      "5\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9996 16.701108685439483 1.5415089602357381 0.8439744900833533\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 16.76198611769552 1.5798666301218038 0.8321188804129954\n",
      "Patience is\n",
      "6\n",
      "\n",
      "\n",
      "train_coverage1.0\n",
      "test_coverage1.0\n",
      "train_width17.507286853135266\n",
      "test_width17.63185805864919\n",
      "pearson0.8406916470326945\n",
      "rmse_train1.5238167570492784\n",
      "rmse_test1.545568421054238\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 266.3026013062423 9.4810296085867 -0.18483428439399865\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 264.6553165004159 9.369225695831945 -0.1742774898657669\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 132.00789538404402 14.578680893946881 0.17577918171525378\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 132.19869134872638 14.016283159802317 0.17440590715018486\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7748 36.10481390233547 14.858064067875974 0.07055720298011456\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.765 36.06517889360325 14.527686426773922 0.0702711907532087\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5548 12.60248371930163 7.998055072530687 0.09312000284261338\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.579 12.546830582731097 7.861235811976697 0.07944996417472514\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6576 5.65218874019333 2.9082446492594984 0.44307367419208826\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.642 5.61978408530224 2.9730909077020335 0.4175895933139167\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.784 4.133835322086299 1.647997776166308 0.7951038508799528\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.757 4.1004009247040765 1.7969384940430426 0.753406039138847\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.856 4.3007835433762995 1.4118892641691254 0.8545535465756812\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.832 4.263107709713815 1.5509403601627851 0.8217759345039775\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8644 4.336270022677257 1.3951383396745372 0.8581604725692478\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.84 4.282651374205259 1.538230347420287 0.8259169973341891\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8728 4.450303629891358 1.3902085090669565 0.8591858051528819\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.847 4.412531290430587 1.5290357080861818 0.8279001934866521\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8716 4.41393595338977 1.3898984582373353 0.8593187769885277\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.853 4.3719910283214505 1.5224815811838268 0.8288171024586611\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8812 4.542408019740018 1.3884447004701326 0.859556699081763\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.856 4.500334373138123 1.5253999413612869 0.8287240501180203\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8688 4.439494377777273 1.3879520217441044 0.8596866705724242\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.849 4.401687876333077 1.5311916157181462 0.8272019033777125\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8832 4.603641094146752 1.3874454197893962 0.859804948381594\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.859 4.577072173258938 1.5236653319243314 0.8289075329607548\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8796 4.45903224487866 1.3870801647324449 0.8598455502587096\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.851 4.407626237196004 1.5339963158786392 0.8266585681778233\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8788 4.4334407266310105 1.387203015189826 0.8599157378484135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.849 4.416948322673557 1.5285196642842536 0.8284338027159993\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8728 4.399311833099147 1.3868283146659168 0.8599014012814944\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.846 4.3672148489005655 1.533158254299441 0.8267892819995623\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8644 4.351050563219717 1.3862617301484828 0.8600633565679972\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.838 4.289566914975052 1.5299017020356636 0.8277488548739156\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8676 4.388748946634193 1.3862264117773735 0.8600374588521496\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.843 4.341892475470692 1.52766469975138 0.8282427924986332\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8668 4.3440890121915325 1.3867542082455975 0.8599494301758742\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.851 4.318996431153147 1.526258486585657 0.8287532917047828\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8712 4.411363356563011 1.385627921546339 0.8601762996872601\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.844 4.3605442693224585 1.5312164790326048 0.8272814323150718\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.8712\n",
      "test_coverage0.844\n",
      "train_width4.411363356563011\n",
      "test_width4.3605442693224585\n",
      "pearson0.8272814323150718\n",
      "rmse_train1.385627921546339\n",
      "rmse_test1.5312164790326048\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 294.4134936675959 9.253441794042198 -0.009595711399153911\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 293.0198830674975 9.452407942129836 -0.07278156844155693\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 126.04445325905033 11.104315816651626 -0.07611083011624406\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 125.61484029360764 11.406213880528627 -0.04126307895269556\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9104 34.00957975404514 9.945361922894163 0.10521048507066455\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.912 33.81344888183863 10.10520381751402 0.09008411390015104\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.636 14.285477667338307 7.920741612277486 0.2904629738181784\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.654 14.253282300318658 7.856791377197667 0.3024046722636084\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7708 7.7885654218004285 3.3254871478528574 0.557295365239957\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.749 7.817153093604901 3.3585413323883 0.5457595443086248\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9056 6.351775527343918 1.8118504826199082 0.7700971980915952\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.902 6.363363310541785 1.8809703535294258 0.7501304203010126\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9272 5.945030570920106 1.5602720894262996 0.8361514974530383\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.918 5.955922458055368 1.6141868691547883 0.8225846678802372\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9408 6.200897749248275 1.50718659469348 0.8473435491807126\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.939 6.207485010627673 1.5662345836868548 0.8339735317413501\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9488 6.321907142346863 1.4934898253377618 0.8500129059873193\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.938 6.349583761218001 1.543563802950976 0.8387594982029503\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9468 6.291106730250704 1.4826910281112018 0.8525908689652166\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.936 6.287466068641212 1.5331091494756182 0.8417436557051082\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9444 6.257610752629318 1.4793913411188255 0.8531151339758707\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.935 6.298954488970179 1.5248767786472754 0.8430009848613479\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9436 6.165075687139634 1.4752822956285128 0.8540169610094709\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.939 6.199564376310602 1.5262402850910652 0.8426719578509818\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9428 6.191351319867467 1.4790384946359278 0.8532619579304935\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.933 6.227532988344198 1.5272456203863767 0.8430644525054988\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.944 6.274211467686862 1.4750791995975672 0.8540061305007584\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.937 6.3002361204712285 1.5215666011571976 0.8439325341738553\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.944 6.20912296908337 1.4740959695498002 0.8542150396526549\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.939 6.243249227121996 1.5261271405068557 0.842925080915559\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9448 6.245106279495016 1.4732304145643633 0.8545503027186803\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.937 6.2975919020039415 1.5234349216696152 0.8439714153999589\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9428 6.1417045621468525 1.475168774980207 0.8540490663756958\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.931 6.168773197442767 1.5261159251215177 0.8430918176024775\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9496 6.298746611301859 1.4750184621437405 0.8541236598476842\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.941 6.318372716797405 1.521132585115429 0.8444290795754482\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9444 6.331968684652128 1.4753871017083857 0.853936014724764\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.943 6.345252376462745 1.5227059384546984 0.8437018352517761\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.942 6.1989354607283556 1.4791886903748204 0.8531201837387714\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.933 6.2139375829971675 1.5193452543449004 0.844312853200756\n",
      "Patience is\n",
      "4\n",
      "\n",
      "\n",
      "train_coverage0.9448\n",
      "test_coverage0.937\n",
      "train_width6.245106279495016\n",
      "test_width6.2975919020039415\n",
      "pearson0.8439714153999589\n",
      "rmse_train1.4732304145643633\n",
      "rmse_test1.5234349216696152\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 243.13711350883167 8.633504385553051 0.17950913938005342\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 240.4637157655249 8.357833060971034 0.11323013262844613\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 93.76080532112812 10.087056039074264 0.3066670286144662\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 92.87703748669482 9.614796309896855 0.30848381994100343\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9464 28.689665905741368 7.7638487724214755 0.3554047973866689\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.94 28.30933457984338 7.304540727789279 0.3360953883820937\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7164 7.8160585979859 3.7788751527608078 0.6315586893239159\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.723 7.7507154312791275 3.594365701687234 0.6494295339687184\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7256 4.215565607177729 1.9266297942573696 0.7606423483113232\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.729 4.195596602100474 1.8647746379243204 0.7648403043427908\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7588 3.751677481111214 1.57654441455197 0.838818672966456\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.752 3.7366752982235685 1.5733518120912928 0.828360135044219\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7928 3.8592587321603498 1.5258902293632821 0.849405631750682\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.78 3.844659542332315 1.5484839913627604 0.8348315087786727\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8012 3.9328867283604194 1.5154590606730256 0.8516843800151812\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.787 3.9192751920520306 1.5401197915559364 0.8362114916918062\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8036 3.9476516595858806 1.5142337210835735 0.851902677070063\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.794 3.9269507218753468 1.5456693592887054 0.8357717775372777\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.9458040081924626 1.5112191527860594 0.8525288885478545\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.793 3.9388808395774095 1.5367058262930648 0.8371485134320165\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8092 4.007450283045689 1.5109861845329022 0.8526338608162757\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.792 3.9896182954623445 1.5362830167391548 0.8371042309738657\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8108 3.935376243494115 1.5106606632539916 0.8526812195298301\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.798 3.9308202178995617 1.5356091517314612 0.8376589740625567\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8164 4.030003534531722 1.511261154589803 0.8525158254299305\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.796 4.027161881241663 1.5393505409499408 0.836959154815034\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8148 4.033087117684783 1.5105774593291619 0.8526729857538561\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.796 4.002286927740867 1.5395068435870318 0.8370587419710216\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.816 4.08130788752272 1.5098275949545543 0.8528153055460982\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.802 4.060625229816231 1.5353961864668793 0.8376538636940778\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8184 4.093798685763288 1.513216537085521 0.8522030303093668\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.803 4.056831391821157 1.5393328983304835 0.8362846923550081\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8076 4.032226648106633 1.5126289104565656 0.8522701045417141\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.785 4.018243098105369 1.5374686546867407 0.8368366890232023\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.824 4.0642911741959615 1.5092028339485626 0.8529706105372111\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.808 4.034083358730919 1.53855760502177 0.8367878056899878\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.816 4.092119629202178 1.5096817488994674 0.8528585280273645\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 4.062153091343897 1.5424578747493942 0.8365370841479989\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8136 3.9987127314672644 1.5086944281462797 0.8530850195398967\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.803 3.981871140402781 1.5365486794987833 0.8372048354654795\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.8136\n",
      "test_coverage0.803\n",
      "train_width3.9987127314672644\n",
      "test_width3.981871140402781\n",
      "pearson0.8372048354654795\n",
      "rmse_train1.5086944281462797\n",
      "rmse_test1.5365486794987833\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 237.86771516759686 8.8020828390149 -0.11273275275293662\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 235.53110944561374 8.780448238445803 -0.1447365587742304\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9944 136.81052718168635 26.94080812263964 -0.04507479096390726\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.998 135.42121623290214 26.8634728387877 -0.05304108178483419\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6784 30.56298111979852 13.747400085613522 0.04500541031960195\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.671 30.137588198444146 13.842626462169216 0.04477674134353669\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.45 7.531093363032448 5.899400795089778 0.20076719294862477\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.455 7.4539595880342375 5.812206650921492 0.20142220987177362\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.578 4.048028072909678 2.452564771700786 0.6009942362281259\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.582 4.050549965555933 2.4233925947451382 0.6095460033048986\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7036 3.3588168745872724 1.625403964994615 0.8198828032236073\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.722 3.3524903625501428 1.6074264123958493 0.8213346879660584\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7516 3.4327136812058927 1.4992129291085223 0.8487343322302027\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.765 3.4285007478601592 1.5210069043037215 0.8422445308218983\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7584 3.459812435166383 1.486945430846185 0.8513734215798184\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.763 3.463796854220981 1.5076894437786077 0.8452412579160784\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7652 3.5265831244421295 1.4835667752070936 0.8520655167055584\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.768 3.537791531373233 1.5079921426609517 0.8451785512606957\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7564 3.4449975408846263 1.4813937095427487 0.8525647834076009\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.75 3.4540873853477643 1.5029912085716017 0.8463511687162422\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7576 3.457786352724132 1.4806785823833895 0.8526906504165535\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.754 3.4556625088353807 1.5041485119887268 0.845827617191089\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7632 3.527023683118663 1.4797734225295622 0.852928015418249\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.761 3.523775038082946 1.505686986494483 0.8457539031551823\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7764 3.6296479351445092 1.4792185422191122 0.8530377928994881\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.776 3.6432137365957424 1.5130621462954215 0.8437508595751836\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7744 3.59298809659878 1.4792943231490567 0.8530190036960907\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.773 3.5913452688068883 1.5069098652876503 0.8455892514406669\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.774 3.570893088847417 1.4776821672016391 0.853349421309527\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.765 3.571388714847936 1.508328631554707 0.8450071838927409\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7708 3.519996378177752 1.477648081643729 0.8533638658612714\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.77 3.542640641477552 1.5092974939187513 0.844684848027417\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7728 3.566058699619453 1.4767732298454213 0.8535284894886863\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.767 3.5665584633914142 1.5056638736658128 0.8455748370387534\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7744 3.5569580288112586 1.4765024886439868 0.8535841993554049\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.77 3.560877734088649 1.506143412047689 0.8454898594294493\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7808 3.6046904479060906 1.477824849461535 0.853544690846426\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.781 3.6166076868612547 1.5123574377908855 0.8450267179836338\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7804 3.6135562553952068 1.4762148572347302 0.8536808194544357\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.773 3.623137299013188 1.510691686378211 0.8447000269066487\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.7804\n",
      "test_coverage0.773\n",
      "train_width3.6135562553952068\n",
      "test_width3.623137299013188\n",
      "pearson0.8447000269066487\n",
      "rmse_train1.4762148572347302\n",
      "rmse_test1.510691686378211\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 208.83940923051475 6.421020287777623 -0.4458546742464495\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 209.77976277881152 6.217448684960311 -0.43644954340649716\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 60.977940548342 5.527131985718996 0.16529166824808195\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 60.71450799025857 5.614687527360787 0.17911355530716605\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9148 23.435223887345895 6.423024581503377 0.1818200192747887\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.902 23.327684143378097 6.621369667228031 0.17066317095574446\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.68 8.35343982222906 4.183925175844139 0.1092068485828498\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.675 8.36416905152327 4.253413025659892 0.09399330485131938\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6948 4.190410850405205 2.139551697134774 0.6760877699419774\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.679 4.176682692795558 2.179963994374895 0.6609638984244082\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7388 3.411521494373269 1.5594973786397859 0.8339014392134387\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.715 3.4072766783881505 1.5922188240386432 0.8300235588780623\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7664 3.534752816257451 1.4876413464131926 0.8493605971494935\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.77 3.536021810948695 1.5077006322749067 0.8476358385376109\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7672 3.4542969146492193 1.4785231480646972 0.8513726753215818\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.758 3.4408382243182825 1.504283188910897 0.848113987898788\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7652 3.4717829162297233 1.4717400722514538 0.8528593932857298\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.76 3.451115322427931 1.4997994379192163 0.8492852126574186\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7844 3.6127608511846883 1.4690360498675916 0.8534325327156956\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.769 3.610250535841494 1.5032862399742266 0.848264670173043\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7664 3.499188866378193 1.4681452697062873 0.8535886093609693\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.767 3.5072383343910376 1.4987730997805466 0.8489925965570652\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7748 3.554918511343321 1.4678465171516506 0.8537025495656085\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.766 3.5583848425851845 1.4968810184427743 0.8493322882108545\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7764 3.5488901922557634 1.4679361029067555 0.8537834404133072\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.772 3.54470538535582 1.504503325533294 0.8481826698989552\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7808 3.55275828465979 1.4666989149074905 0.8538779906435877\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.77 3.561653824125232 1.5025973774133983 0.8482549537882207\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7768 3.591719962576803 1.4668347467178755 0.8540340110840134\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.763 3.58637828777441 1.50012156062983 0.8488423163884476\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7752 3.5206937538413507 1.4660281835833773 0.8540360304241426\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.769 3.514407600477696 1.504532909803635 0.8480262017359378\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.782 3.578763135180901 1.4663217381344331 0.8539837467133782\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.771 3.5671610261882742 1.5022897417704788 0.8482986151587771\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7844 3.6313985375105258 1.4659111592986624 0.8540933038772122\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.777 3.6333530583945888 1.5072307839413228 0.8474924207469234\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7816 3.6170866593824256 1.4655198905278406 0.8541632176051103\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.783 3.608214775854772 1.5013680619978433 0.8483753088251302\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.766 3.4698076107459026 1.4655055222391684 0.8541659496657135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.761 3.475337442886235 1.5041833243338065 0.8479588927022053\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.766\n",
      "test_coverage0.761\n",
      "train_width3.4698076107459026\n",
      "test_width3.475337442886235\n",
      "pearson0.8479588927022053\n",
      "rmse_train1.4655055222391684\n",
      "rmse_test1.5041833243338065\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 277.58779337299876 6.817135275434739 0.08989695268342539\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 271.32189671051407 6.76187732862939 0.11547515083299784\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 171.86784317130176 16.414223940579507 0.10855513431582135\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 169.3605837454975 15.470383548540045 0.03984614793140165\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7148 40.09943145102181 18.156900996065026 0.2830005207598095\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.742 39.318448175791154 17.173318457104028 0.24376230536859209\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5388 11.32456479331599 7.111329595986822 0.393104696752229\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.566 11.21403506595327 6.9000302384184025 0.368561522052749\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.788 6.806797250297253 2.6680236945475526 0.6339335383360586\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.799 6.734792663284253 2.6669923135582323 0.6244118650658385\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8508 4.976765587275312 1.6825693019212549 0.8112377361167357\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.861 4.887760732334929 1.6571246475824868 0.8023789218246828\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8888 5.260402756306143 1.5408341340801694 0.8436999287037275\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.905 5.177001143221849 1.5022042665234674 0.8383816373995132\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8808 5.0287834261876005 1.5335036332296594 0.8452536057110428\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.889 4.982562495320177 1.499370496291617 0.8396007298061869\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8784 4.955925703826334 1.5281999692391022 0.8464244214546572\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.88 4.890699689440743 1.4970918485278906 0.8398623205957794\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8808 4.924617609748598 1.5260169272774997 0.8469811790113723\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.89 4.861530899404909 1.5046121224390099 0.8380406019281676\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8784 4.90169748544004 1.527239547396592 0.8466638696336459\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.884 4.847823780597418 1.5092216704968757 0.837555075974978\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8688 4.817614287936167 1.5266543506801877 0.846812300360795\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.871 4.764276214397975 1.5097341266964615 0.8368385200535143\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8688 4.754985159694589 1.5250098770534062 0.8471254018792075\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 4.6858414557738755 1.5091706535659077 0.8371808970249724\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 4.752813083617098 1.5255206046914924 0.8470550512339269\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.868 4.685761812167964 1.5133632613111874 0.8357834966671973\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8692 4.769879698536977 1.5234644196941112 0.8474544037590944\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 4.6915494225032255 1.5103983321517778 0.8368473150342994\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.87 4.813382583104773 1.5237573227328898 0.8474157005692571\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.873 4.7559007452305595 1.5154977407046546 0.8361950897710487\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8712 4.806576233563788 1.5228532273887998 0.8476213713624545\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.872 4.72844702049146 1.5171951411029725 0.8350914219787479\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8684 4.794962728195279 1.5227497539563761 0.8476431864237839\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.863 4.713692709699997 1.5188390802860214 0.8355316092685189\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8588 4.709521414635289 1.5232678969789766 0.8475039964016475\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.86 4.668961303379154 1.5139178018778334 0.8363830536808166\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.866 4.639795971669184 1.5244898317425812 0.8472547004904876\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.855 4.5652070232608555 1.5228490242684065 0.834419340888283\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "train_coverage0.8684\n",
      "test_coverage0.863\n",
      "train_width4.794962728195279\n",
      "test_width4.713692709699997\n",
      "pearson0.8355316092685189\n",
      "rmse_train1.5227497539563761\n",
      "rmse_test1.5188390802860214\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 292.54570719347913 8.939421773653555 -0.2373158719794956\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 287.930430180101 8.52942846605408 -0.1397179349959256\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9956 122.05118278036639 17.299347119831307 -0.10656713575573985\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.994 120.73334726327928 18.36421019288869 -0.11897481512847781\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7592 28.38224268637834 12.080715444312322 -0.3331685831206076\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.748 27.93660949493184 12.147779279026953 -0.3277979181407825\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6652 9.092091010849103 5.411611926402808 0.16592223609573414\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.667 8.945790974529235 5.31287227088407 0.15565223936118983\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6668 4.781595614137595 2.4598498649453733 0.570292928001394\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.675 4.716134885375541 2.3893612378265963 0.5564713276622221\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.79 3.9296523910619996 1.5756502752869745 0.8368073984234702\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.767 3.8780027449309347 1.6230583094419941 0.8044402644524327\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8288 4.015455953766229 1.435413297797898 0.8652585157452464\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.811 3.970249625177637 1.5326792489833374 0.8279371490342938\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8384 4.046017792074596 1.4225551118905908 0.8677407693447384\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.816 3.9949507861466835 1.5300075773961017 0.828826754709643\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8412 4.070741689810307 1.4209736394325634 0.8680718246719192\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.82 4.0165927260373175 1.5311097311042752 0.8289913792875483\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.842 4.056499344211504 1.4220611508295076 0.8680093425267323\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.822 4.026051047525796 1.525519964822191 0.8292982674896254\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8356 4.1105516920213665 1.4221792473042558 0.8679075344568137\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.812 4.0573355457343565 1.5331742015842664 0.8292917679386177\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8484 4.1274895245430985 1.4204656141119791 0.8681970147315227\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.826 4.0699733249849315 1.52489022813068 0.8298917970325534\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8476 4.17730058137222 1.4211530013404734 0.8681331354818729\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.83 4.125268689142538 1.5345806489337939 0.8288547571825093\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8384 4.023956460830196 1.4200100748791158 0.8682522670783637\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 3.983655168388802 1.5332285525847762 0.8286082850050709\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8456 4.13952898495897 1.4209050047085046 0.8681068164845679\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.834 4.081151790269892 1.5237859359473522 0.8301604146880476\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8436 4.138093091785998 1.4203238193893648 0.8683448722307063\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.819 4.088931353032615 1.535620120797066 0.828907571779929\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8332 3.997163291428771 1.4215189872913 0.8680510073307882\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.815 3.9508572467715948 1.5256500087917593 0.8294746578515351\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8388 4.052672193839669 1.4197141107271818 0.8683538453945866\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.819 4.0043289918856715 1.5285746586977633 0.8289191204836162\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8412 4.055024537079924 1.4193101264422863 0.8683960326344324\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.811 4.011772438532989 1.5277077001829558 0.8299584215953097\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8508 4.179296761607537 1.4196859194108293 0.8683054843803047\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.837 4.132008799755271 1.5349843169827282 0.8279814284403886\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "train_coverage0.8412\n",
      "test_coverage0.811\n",
      "train_width4.055024537079924\n",
      "test_width4.011772438532989\n",
      "pearson0.8299584215953097\n",
      "rmse_train1.4193101264422863\n",
      "rmse_test1.5277077001829558\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 226.4273385221365 7.162954972964688 -0.015948872755408523\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 225.34656990937108 7.144744579798613 -0.02056553575672281\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 67.71186453910803 7.257904257022789 -0.12860549897984963\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 67.51490127105006 7.24270888509954 -0.12184452724900312\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9136 25.388726635037298 7.103317530700326 -0.011129056959119723\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.926 25.039401038127046 6.899298875216392 -0.009301420997933754\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.628 6.673757461813482 3.75513096242942 0.4205605182954579\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.632 6.587295070654283 3.5857215237648585 0.44157479289335555\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6076 3.413527734239375 2.048736504777501 0.6969546531928221\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.654 3.3995622234669933 1.916290065507191 0.7173366305535106\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6408 2.810913206747795 1.6305381602741966 0.8217413658534428\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.655 2.7981167176254123 1.5310772064659435 0.8280524648868622\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6828 2.8140996365986335 1.511463359055799 0.8467444994424844\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.686 2.7950626580571023 1.4372502516233365 0.8492204453082014\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6972 2.8954844435515916 1.4720645127560188 0.8545331435225225\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.694 2.8779800416312162 1.4308061434226294 0.8525568013060812\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6924 2.8519273682946027 1.4655092029438093 0.8559167759058319\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.689 2.830569567644753 1.42403104285205 0.8537846464055366\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6932 2.8332994883839224 1.4622432557624858 0.8566096318259908\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.678 2.807435857306786 1.426875125215671 0.8527348101593986\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6924 2.8643053641982426 1.4604220348486296 0.8569776698240887\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.694 2.846133948770381 1.424166507345978 0.8535108154385976\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.702 2.926780518730471 1.4602872036390453 0.8570080849280922\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.693 2.895437051721639 1.4238001629072827 0.8535459654140833\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.698 2.8955429079263575 1.4590016726217667 0.8572930685958611\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.698 2.8915791744745576 1.4249550726722413 0.8538959165054943\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6952 2.8453725086845263 1.4595296642015518 0.8571902195735112\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.688 2.8346255335956827 1.4229041766830537 0.8540123930746214\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.6956 2.8699861455688085 1.4594742271322498 0.8572640486955733\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.688 2.844380407103695 1.4212549021727976 0.8538910854586722\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7012 2.9254359274440933 1.459149070385632 0.85725043515342\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.701 2.8975313314579445 1.4242014774938632 0.8537619635164059\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.71 2.9860051875980487 1.458898869293512 0.857318314513019\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.7 2.9593631457519134 1.4208952776376498 0.8540944457856605\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7 2.934341336323251 1.4587413238481923 0.8573442918398655\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.696 2.911748490783002 1.421067542676917 0.8540470659992009\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7116 2.9499959003851344 1.4588423906885086 0.8573192945881757\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.703 2.92555150025167 1.4220218132520044 0.8540644084360857\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7172 3.0206720663612994 1.4585875145384746 0.8573714294277447\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.707 2.9982679459418704 1.4215718328975866 0.8539547210174295\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.7172\n",
      "test_coverage0.707\n",
      "train_width3.0206720663612994\n",
      "test_width2.9982679459418704\n",
      "pearson0.8539547210174295\n",
      "rmse_train1.4585875145384746\n",
      "rmse_test1.4215718328975866\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 348.1079532937511 11.393215099990195 -0.22503897573982068\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 345.743653770778 11.19159721461144 -0.22666074375852688\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 188.93821288587992 22.5355382155643 -0.05719377465712233\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 187.80091911660688 22.53668815677187 -0.06786730807784594\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.7664 76.2532125352302 33.48705451282487 -0.11993378740215604\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.756 75.65825839684062 33.86150643236825 -0.15326173936655882\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.5788 20.599249326338505 13.574743779723283 0.09219538526547563\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.578 20.45843465435406 13.496935774686222 0.06708896011569968\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8236 13.424528285876441 5.221139959458643 0.17477432931855186\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.806 13.378049839321733 5.385716408931822 0.12557279895319576\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.94 8.543054506979784 2.2541535367741177 0.6444553257318679\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.931 8.480969982451471 2.352256529717486 0.6091807912113102\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9684 7.443542633008588 1.569931054260517 0.8398088906643935\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.959 7.402900866151482 1.6386032677263318 0.8243928136980307\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9704 7.460564763297914 1.486293926270039 0.859048960141247\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.964 7.430696970968722 1.5151258635817872 0.8532132030803319\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.974 7.596430581704151 1.470318245484272 0.8610036031436373\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.967 7.531626642986384 1.5097082543360152 0.8532382479955799\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9708 7.583583693348371 1.4739515905273783 0.8604321876668174\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.975 7.548022989030704 1.5131137493418454 0.8525790783950656\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 10\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9688 7.516953879589903 1.4705627447721732 0.8610808893358396\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.966 7.459174105824566 1.5209728444890707 0.8510197948217689\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 11\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9696 7.635571615912397 1.4746969231919302 0.8601532631768631\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.97 7.60231505988505 1.5236419540312949 0.8503017370224634\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 12\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9776 7.820069058368986 1.4700913041119212 0.8611615858714796\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.977 7.796596436806031 1.5049125301292814 0.8544574791162391\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 13\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9736 7.616143270147076 1.4715504903682912 0.8607868414262138\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.971 7.605187769526584 1.5163485977052535 0.8519856006354378\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 14\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9696 7.5428627358264375 1.4763332795297268 0.8597812628636624\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.964 7.490480085110604 1.5116134396994236 0.8528296577647345\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 15\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9692 7.514609770234139 1.4691787919419832 0.8612505444073318\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.969 7.48548198016863 1.516906349526668 0.8517068127904096\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 16\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9676 7.35031620804176 1.4728751740390678 0.8605218422914753\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.966 7.347848342479574 1.517770941806655 0.8516227720507747\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 17\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9684 7.3183780837619965 1.4721637860239887 0.8606757191958956\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.96 7.30808248673183 1.518911118057103 0.8514019110896608\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 18\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9664 7.423651743539491 1.4698107324044396 0.8611194379808931\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.96 7.377908909109006 1.5177967652028195 0.8515102448764703\n",
      "Patience is\n",
      "3\n",
      "\n",
      "\n",
      "epoch number is 19\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9652 7.2223334147948135 1.465646328064373 0.8619751637720315\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.963 7.18415082917067 1.5109408218385572 0.8529741468915034\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "train_coverage0.9652\n",
      "test_coverage0.963\n",
      "train_width7.2223334147948135\n",
      "test_width7.18415082917067\n",
      "pearson0.8529741468915034\n",
      "rmse_train1.465646328064373\n",
      "rmse_test1.5109408218385572\n",
      "epoch number is 0\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 223.56981689639636 5.709793322806472 0.30915936897824675\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 224.9584741403421 5.93335010568807 0.2307799525910766\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 1\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 74.69050783014991 8.608653207948633 0.37664070056111354\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "1.0 74.90435348906313 9.1377173161167 0.3493118472879378\n",
      "Patience is\n",
      "1\n",
      "\n",
      "\n",
      "epoch number is 2\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9628 26.520005146914947 6.215553378814199 0.28322989927652015\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.946 26.527934658606952 6.255363035234886 0.26694672614935583\n",
      "Patience is\n",
      "2\n",
      "\n",
      "\n",
      "epoch number is 3\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8196 9.74881053779009 3.6644568554668746 0.6020781033144746\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.821 9.78268543870521 3.5607739573949133 0.6094944108077418\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 4\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8292 5.530310833888425 1.9566532287816512 0.7629647422148269\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.841 5.5524518486499055 1.9158537409424026 0.7654972917588461\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 5\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8712 5.0133295449889905 1.5486289301397478 0.833149340767694\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.869 5.034324455931772 1.553332020373773 0.8270123712963142\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 6\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8836 5.092522930215663 1.4959869965510555 0.8453463630043685\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.871 5.1112901954651795 1.5222703597643268 0.8344545548622532\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 7\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.8948 5.253821102359104 1.486697662691703 0.8470594071449525\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.894 5.266567890217563 1.5082163969316416 0.8382558821154913\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 8\n",
      "Training Coverage, Widths, RMSE, and Pearson R\n",
      "0.9 5.295008888551088 1.480012734234215 0.848557768710219\n",
      "Testing Coverage, Widths, RMSE, and Pearson R\n",
      "0.894 5.315858236093783 1.5026518822576465 0.8395205119172071\n",
      "Patience is\n",
      "0\n",
      "\n",
      "\n",
      "epoch number is 9\n"
     ]
    }
   ],
   "source": [
    "catch_overall = []\n",
    "\n",
    "for idx in range(0,50): \n",
    "    best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r, _, _ = get_results(idx, var_weights = 2.0, var_weight_weights = 1.0, var_D = 1, inflation_factor =1, fudging_beta = beta(1,19), \n",
    "           fudging_var = 5e-3, epochs = 20)\n",
    "    \n",
    "    catch_overall.append([best_train_width, best_coverage_train, best_rmse_train, best_test_width, best_coverage_test, best_rmse_test, best_pearson_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538d375-2e01-411d-a7fb-a9781b542b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data//catch_overall_50_reps_c1.pickle\", \"wb\") as f: \n",
    "    pickle.dump(catch_overall,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612af96-39d1-4cc1-b8c1-1370a929dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.DataFrame(catch_overall).iloc[:,:7]\n",
    "overall_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac8a39-4c27-4a53-ab07-13730e0c031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.columns = ['best_train_width', 'best_coverage_train', 'best_rmse_train',\n",
    "                      'best_test_width', 'best_coverage_test', 'best_rmse_test', 'best_pearson_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1508f29-167b-4e36-9b48-7a5703da2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
